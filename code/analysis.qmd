---
title: "Machine Learning Method Application to Covid-19 Dataset"
author: ""
date: today
format:
  html:
    toc: true
    toc-title: Contents
    toc-depth: 2
    toc-expand: 1
    smooth-scroll: true
    theme:
      light: lumen
      dark: superhero
number-sections: true
number-depth: 2
editor: visual
execute:
  warning: false
  cache: true 
keep-md: true
title-block-banner: true
---

# Preparation

Load all related packages, and define hyper-parameters from the very beginning. To ensure reproductivity, all seed are set to the fixed value `seed`.

```{r}
library(tidyverse) # data cleaning
library(knitr) # display tables in good format
library(caret) # confusion matrics
library(bnclassify) # BN
library(kernlab) # SVM
library(randomForest) # random forest
library(C50) # C5.0 decision tree
```

```{r}
# set hyperparameters
path_csv <- "../Data/patient.csv"
seed <- 9
```

# Data

## Loading

First of all, load the raw data. There are 95839 samples and 20 features (including the response variable) here.

```{r}
df <- read.csv(path_csv)
dim(df)
kable(head(df), format = "html")
```

## Cleaning

Aiming to solve the binary classification problem, binary `y` should be elicited first. As for features, not all of them are available. For example, `pneumonia = 99` indicate the feature `pneumonia` is not available for this sample. In this case, we should label `99` as `NA` to avoid future mistakes.

```{r}
df_ageori <- df %>% mutate(y = factor(ifelse(death_date == "9999-99-99", 0, 1),
                                      labels = c("live", "die")),
                           pregnant = factor(ifelse(pregnant == 1, 1, 2)),
              across(c(sex, patient_type, intubated, pneumonia,
                       diabetes, copd, asthma, immunosuppression, hypertension,
                       other_diseases, cardiovascular, obesity, chronic_kidney_failure,
                       smoker, another_case, icu, outcome), ~ factor(ifelse(.>2, NA, .)))) %>%
  select(-c(death_date))
df_agefac <- df_ageori %>% mutate(age = factor(age))
kable(head(df_agefac), format = "html")
```

# Model

In this part, we managed to reproduce the result in the papar [Classification of Covid-19 Dataset with Some Machine Learning Methods](https://dergipark.org.tr/en/pub/jauist/issue/55760/748667). machine learning classifier methods are considered:

-   NaiveBayes

-   BayesNet

-   SVM

-   Random Forest

-   Decision Tree

-   KNN

## NaiveBayes

NaiveBayes assumes all variables are independent from each other. By experience, it works relatively well even if the assumptions are not met.

```{r, eval = FALSE}
df <- na.omit(df_agefac) # use factorized age version 
set.seed(seed)
model_nb <- nb('y', df)
model_nb <- lp(model_nb, df, smooth = 1) # learn parameter
cv(model_nb, df, k = 10) # cross validation
pred_nb <- predict(model_nb, df)
confusionMatrix(pred_nb, df$y)
```

```{r, echo = FALSE, eval = FALSE}
save.image(file = "model/model_nb.RData")
```

```{r, echo = FALSE}
load(file = "model/model_nb.RData")
confusionMatrix(pred_nb, df$y)
```

## BayesNet

Different from Naive Bayes, Bayes net

```{r, eval = FALSE}
set.seed(seed)
model_bn <- tan_cl('y', df, score = 'aic')
model_bn <- lp(model_bn, df, smooth = 1)
cv(model_bn, df, k = 10)
pred_bn <- predict(model_bn, df)
confusionMatrix(pred_bn, df$y)
```

```{r, echo = FALSE, eval = FALSE}
save.image(file = "model/model_bn.RData")
```

```{r, echo = FALSE}
load(file = "model/model_bn.RData")
confusionMatrix(pred_bn, df$y)
```
## SVM

```{r, eval = FALSE}
df <- na.omit(df_ageori)
set.seed(seed)
train_control <- trainControl(method = "cv", number = 10)
model_svm <- train(y ~ ., data = df, method = "svmRadial", trControl = train_control)
pred_svm <- predict(model_svm, df)
confusionMatrix(pred_svm, df$y)
```


```{r, echo = FALSE, eval = FALSE}
save.image(file = "model/model_svm.RData")
```

```{r, echo = FALSE}
load(file = "model/model_svm.RData")
confusionMatrix(pred_svm, df$y)
```

## Random Forest

```{r, eval = FALSE}
set.seed(seed)
df <- na.omit(df_ageori)
train_control <- trainControl(method = "cv", number = 10)
model_rf <- train(y ~ ., data = df, method = "rf", trControl = train_control)
pred_rf <- predict(model_rf, df)
confusionMatrix(pred_rf, df$y)
```


```{r, echo = FALSE, eval = FALSE}
save.image(file = "model/model_rf.RData")
```

```{r, echo = FALSE}
load(file = "model/model_rf.RData")
confusionMatrix(pred_rf, df$y)
```

## Decision Tree (C4.5)

```{r, eval = FALSE}
set.seed(seed)
train_control <- trainControl(method = "cv", number = 10)
model_tree <- train(y ~ ., data = df, method = "C5.0", trControl = train_control)
pred_tree <- predict(model_tree, df)
confusionMatrix(pred_tree, df$y)
```


```{r, echo = FALSE, eval = FALSE}
save.image(file = "model/model_tree.RData")
```

```{r, echo = FALSE}
load(file = "model/model_tree.RData")
confusionMatrix(pred_tree, df$y)
```

## kNN



```{r, eval = FALSE}
set.seed(seed)
train_control <- trainControl(method = "cv", number = 10)
model_knn <- train(y ~ ., data = df, method = "knn", trControl = train_control)
pred_knn <- predict(model_knn, df)
confusionMatrix(pred_knn, df$y)
```


```{r, echo = FALSE, eval = FALSE}
save.image(file = "model/model_knn.RData")
```

```{r, echo = FALSE}
load(file = "model/model_knn.RData")
confusionMatrix(pred_knn, df$y)
```

# Summary

In this part, we summarize all the results above to reproduce the main result table in the original paper

accuracy
precision
F-measure
recall

```{r}
get_all_scores <- function(pred, y = df$y){
  acc <- accuracy(pred, y)
  prec <- precision(pred, y)
  rec <- recall(pred, y)
  F1 <- 2*(prec*rec)/(prec+rec)
  return(c(acc, prec, F1, rec))
}
```

```{r, echo = FALSE}
# recovery
load(file = "model/model_bn.RData")
df <- na.omit(df_ageori)
```


```{r}
pred_list <- list(pred_nb, pred_bn, pred_svm, 
                  pred_rf, pred_tree, pred_knn)
summary_table <- do.call(rbind, lapply(pred_list, get_all_scores))
summary_table <- round(summary_table, 3)
colnames(summary_table) <- c("Accuracy", "Precision", "F1", "Recall")
summary_table <- cbind(data.frame(Model = c("NaiveBayes", "BayesNet", "SVM", "RandomForest", "DecisionTree", "kNN")), summary_table)
kable(summary_table, format = "html")
```




















